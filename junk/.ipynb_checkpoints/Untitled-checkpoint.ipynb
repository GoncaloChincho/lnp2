{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = 'aposta'\n",
    "if word == 'aposta':\n",
    "    final_filename = '../apostaAnotado.final'\n",
    "    unigrams_path = 'apostaUNIGRAMAS.txt'\n",
    "    bigrams_path = 'apostaBIGRAMAS.txt'\n",
    "else:\n",
    "    final_filename = 'foremAnotado.final'\n",
    "    unigrams_path = 'foremUNIGRAMAS.txt'\n",
    "    bigrams_path = 'foremBIGRAMAS.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_uniq(list):\n",
    "    uniq = []\n",
    "    for el in list:\n",
    "        if not el in uniq:\n",
    "            uniq.append(el)\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ngrams should be a dictionary -> {'the vaporwave': 50, 'kill jill': 542}\n",
    "def ngrams_to_file(word,ngram_counts,n):\n",
    "    if n == 1:\n",
    "        filename = word + 'Unigramas.txt'\n",
    "    elif n == 2:\n",
    "        filename += word + 'Bigramas.txt' \n",
    "    else:\n",
    "        return 'Bad n!'\n",
    "\n",
    "    file = open(filename,'w')\n",
    "\n",
    "    for ngram in ngram_counts:\n",
    "        if n == 2:\n",
    "            ngram_write = ngram[0] + ' ' + ngram[1]\n",
    "        else:\n",
    "            ngram_write = ngram\n",
    "        \n",
    "        file.write(ngram_write + '\\t' + str(ngram_counts[ngram] + 1) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(final_filename,'r')\n",
    "text =(file.read()).lower()\n",
    "text_words = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list_uniq(text_words)\n",
    "vocab.append('<s>')\n",
    "vocab.append('</s>')\n",
    "n_tokens = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_counts = Counter()\n",
    "\n",
    "\n",
    "for token in vocab:\n",
    "    unigram_counts[token] = 0\n",
    "\n",
    "for text_word in text_words:\n",
    "    unigram_counts[text_word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_to_file(word,unigram_counts,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "for i in range(len(vocab) - 1):\n",
    "    bigrams.append((vocab[i],vocab[i]))\n",
    "    for j in range(i + 1,len(vocab)):\n",
    "        bigrams.append((vocab[i],vocab[j]))\n",
    "        bigrams.append((vocab[j],vocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_bigrams = list(ngrams(text_words,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_counts = Counter()\n",
    "\n",
    "for bigram in bigrams:\n",
    "    bigram_counts[bigram] = 0\n",
    "\n",
    "for text_bigram in text_bigrams:\n",
    "    bigram_counts[text_bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_to_file(word,bigram_counts,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15234\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4027\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15235\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8110378\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
